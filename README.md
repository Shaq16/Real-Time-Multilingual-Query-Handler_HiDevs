ğŸš€ Real-Time Multilingual Query Handler

A robust Retrieval-Augmented Generation (RAG) system that breaks language barriers.
This application allows users to ask customer support questions in any language, automatically:

Detects the language

Translates user input to English

Searches a custom multilingual knowledge base

Generates an accurate response

Translates the answer back to the userâ€™s preferred language

ğŸ“¸ Application Screenshots
1. Main Interface

A simple chat UI where users ask questions in their native language.
<img width="1919" height="939" alt="image" src="https://github.com/user-attachments/assets/96db269b-4bf2-45c1-82fa-b74c40f6b3ad" />
2. Multilingual Response Example

The system detects Hindi â†’ translates â†’ retrieves context â†’ answers â†’ translates back to Hindi.

âœ¨ Features

ğŸŒ Language Agnostic â€” Supports 7+ languages (Spanish, French, Hindi, Chinese, Arabic, German, etc.)

âš¡ Ultra-Fast Inference â€” Powered by Groq Llama-3.3 models via Groq API

ğŸ” RAG Pipeline â€” Uses ChromaDB + sentence-transformer embeddings to return accurate answers

ğŸ”„ Real-Time Translation â€” Automatic translation of user queries and responses

ğŸ“– Transparent Debug Info â€” Shows detected language, translated text, and context documents

ğŸ§  Chat Memory â€” Maintains conversation history for follow-up questions

ğŸ—ï¸ Modular Code Structure â€” Easy to update, extend, and maintain

ğŸ–¥ï¸ Streamlit UI â€” Clean and responsive frontend

ğŸ§° Tech Stack
Frontend

Streamlit

Backend

Python 3.10+

Groq API (Llama-3.3-70b-versatile)

Sentence-Transformers (all-MiniLM-L6-v2)

ChromaDB (Vector Search)

LangChain (Orchestration)

ğŸ“‚ Project Structure
multilingual-query-handler/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Raw text files for knowledge base
â”‚   â”œâ”€â”€ processed/      # Cleaned data
â”‚   â””â”€â”€ chunks/         # Chunked text
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # API keys & model configs
â”‚   â”œâ”€â”€ data_collection.py  # PDF/Text/Web loaders
â”‚   â”œâ”€â”€ preprocessing.py    # Cleaning pipeline
â”‚   â”œâ”€â”€ chunking.py         # Splitting text into chunks
â”‚   â”œâ”€â”€ embeddings.py       # Embedding & vector store management
â”‚   â”œâ”€â”€ translation.py      # Translation logic using Groq
â”‚   â””â”€â”€ query_engine.py     # Core RAG logic
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py              # Streamlit chat frontend
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_translation.py
â”‚   â”œâ”€â”€ test_query.py
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ main.py                 # Build knowledge base pipeline
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation

ğŸ› ï¸ Installation & Setup
1. Clone the Repository
git clone https://github.com/your-username/Real-Time-Multilingual-Query-Handler.git
cd Real-Time-Multilingual-Query-Handler

2. Create Virtual Environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3. Install Dependencies
pip install -r requirements.txt

4. Add API Keys (.env)

Create a .env file:

GROQ_API_KEY=your_key_here
MONGODB_URI=your_mongo_uri

ğŸ§© Building the Knowledge Base

Run the pipeline to clean â†’ chunk â†’ embed â†’ store data:

python main.py

ğŸ’¬ Run the Chat Interface
streamlit run ui/app.py


Then open the displayed URL to start chatting.

ğŸ§  How the System Works

1. Input Detection
Auto-detects language using Groq models.

2. Translation to English
Ensures knowledge base consistency.

3. Vector Search (RAG)
Uses ChromaDB + embeddings.

4. Answer Generation
LLM constructs the final response.

5. Translate Back to User Language
Ensures localized output.

ğŸ§ª Running Tests
pytest tests/

ğŸ¤ Contributing

Pull requests are welcome!
Feel free to improve translations, model selection, or add features.

ğŸ“œ License

This project is licensed under the MIT License.

ğŸŒŸ Acknowledgments

Groq for blazing fast inference

LangChain & Sentence-Transformers

Streamlit for UI simplicity
